{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. What is a time series, and what are some common applications of time series analysis?\n",
        "Ans: \\\n",
        "\n",
        "A **time series** is a sequence of data points collected or recorded at successive points in **time**, usually at equally spaced intervals (e.g., hourly, daily, monthly).\n",
        "\n",
        "Each observation in a time series is typically dependent on previous values, making time series data **temporally ordered** — unlike regular datasets where observations are independent.\n",
        "\n",
        "---\n",
        "\n",
        "###  Example:\n",
        "| Date       | Temperature (°C) |\n",
        "|------------|------------------|\n",
        "| 2025-01-01 | 22.5             |\n",
        "| 2025-01-02 | 21.7             |\n",
        "| 2025-01-03 | 20.9             |\n",
        "| ...        | ...              |\n",
        "\n",
        "---\n",
        "\n",
        "###  Key Characteristics:\n",
        "- **Trend**: Long-term increase or decrease in the data.\n",
        "- **Seasonality**: Repeating patterns over fixed periods (e.g., daily, weekly, yearly).\n",
        "- **Cyclic Patterns**: Irregular fluctuations not tied to seasonality.\n",
        "- **Noise**: Random variation or residual error.\n",
        "\n",
        "---\n",
        "\n",
        "###  Common Applications of Time Series Analysis:\n",
        "\n",
        "| Domain            | Application Example                             |\n",
        "|-------------------|--------------------------------------------------|\n",
        "| **Finance**        | Stock price prediction, risk modeling           |\n",
        "| **Economics**      | GDP forecasting, inflation analysis             |\n",
        "| **Weather/Climate**| Temperature forecasting, rainfall prediction    |\n",
        "| **Healthcare**     | Monitoring patient vitals (e.g., ECG, heart rate)|\n",
        "| **Energy**         | Electricity demand forecasting                  |\n",
        "| **Retail**         | Sales forecasting, inventory planning           |\n",
        "| **Web Analytics**  | Traffic monitoring, trend detection             |\n",
        "| **Manufacturing**  | Predictive maintenance using sensor data        |\n",
        "\n",
        "---\n",
        "\n",
        "###  Why It’s Important:\n",
        "Time series analysis helps in:\n",
        "- **Forecasting future events** (e.g., demand, prices)\n",
        "- **Detecting anomalies** (e.g., spikes, drops)\n",
        "- **Understanding temporal patterns** in historical data"
      ],
      "metadata": {
        "id": "K4SimLZaLsco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. What are some common time series patterns, and how can they be identified and interpreted?\n",
        "Ans: \\\n",
        "\n",
        "##  Common Time Series Patterns\n",
        "\n",
        "Time series data often exhibits a combination of **several patterns**, and identifying these is crucial for effective modeling and forecasting.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Trend**\n",
        "- **Definition**: A long-term increase or decrease in the data.\n",
        "- **Example**: Rising temperature due to global warming.\n",
        "- **How to Identify**:\n",
        "  - Plot the time series: Look for upward or downward sloping lines.\n",
        "  - Use moving averages or trendlines to smooth the series.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Seasonality**\n",
        "- **Definition**: Regular, repeating patterns over fixed time intervals.\n",
        "- **Example**: Ice cream sales peaking every summer.\n",
        "- **How to Identify**:\n",
        "  - Plot data by time intervals (e.g., monthly, weekly).\n",
        "  - Seasonal decomposition methods (like STL).\n",
        "  - Look for repeating spikes/dips at the same intervals.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Cyclic Patterns**\n",
        "- **Definition**: Repeating patterns that **don’t follow a fixed calendar**; often tied to economic or business cycles.\n",
        "- **Example**: Boom and bust periods in the economy.\n",
        "- **How to Identify**:\n",
        "  - Harder to detect than seasonality.\n",
        "  - Look for undulating curves over long periods.\n",
        "  - Often identified using smoothing or filtering techniques.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Noise (Irregular or Random Component)**\n",
        "- **Definition**: Random variation that cannot be explained by trend or seasonality.\n",
        "- **Example**: Sudden one-day drop in sales due to a blackout.\n",
        "- **How to Identify**:\n",
        "  - After removing trend/seasonality, the leftover \"randomness\" is noise.\n",
        "  - No clear pattern or structure.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Level**\n",
        "- **Definition**: The baseline value of the series (constant average when no trend/seasonality).\n",
        "- **How to Identify**:\n",
        "  - Visible as the average around which data fluctuates when other patterns are removed.\n",
        "\n",
        "---\n",
        "\n",
        "###  Visual Example (Pattern Breakdown):\n",
        "Let’s say we analyze monthly sales data:\n",
        "\n",
        "- You might see a **trend** upward over years (business growth).\n",
        "- Within each year, there are repeating **seasonal** spikes in December (holiday shopping).\n",
        "- Occasionally, a big dip due to economic slowdown (a **cyclic** dip).\n",
        "- Random small fluctuations day-to-day (pure **noise**).\n",
        "\n",
        "---\n",
        "\n",
        "##  Tools to Identify These Patterns\n",
        "\n",
        "| Method                         | Purpose                        |\n",
        "|-------------------------------|--------------------------------|\n",
        "| Line plots                    | Visual inspection of patterns |\n",
        "| Rolling averages              | Smoothing to highlight trend  |\n",
        "| Seasonal Decomposition (STL)  | Separate trend, seasonality, residuals |\n",
        "| Autocorrelation (ACF) plots   | Check seasonality & lag effects |\n",
        "| Fourier Transforms            | Detect periodic (seasonal) signals |\n",
        "| Time Series Decomposition     | Breaks data into components   |\n",
        "\n",
        "---\n",
        "\n",
        "###  Summary Table\n",
        "\n",
        "| Pattern     | What it Means                          | Tool to Detect               |\n",
        "|-------------|-----------------------------------------|------------------------------|\n",
        "| Trend       | Long-term upward or downward movement   | Moving averages, line plot   |\n",
        "| Seasonality | Regular repeating pattern (e.g. yearly) | STL, ACF plot                |\n",
        "| Cyclic      | Irregular ups and downs                 | Smoothing, economic context  |\n",
        "| Noise       | Random variation                        | Residual analysis            |\n",
        "| Level       | Baseline value                          | Mean or median               |"
      ],
      "metadata": {
        "id": "4YAEZkraMHbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. How can time series data be preprocessed before applying analysis techniques?\n",
        "Ans: \\\n",
        "Great question! Time series preprocessing is **crucial** for accurate modeling and forecasting. Poorly preprocessed data can lead to misleading patterns or incorrect predictions.\n",
        "Ans: \\\n",
        "\n",
        "### 1. **Handling Missing Values**\n",
        "- **Why**: Time series data often has gaps due to sensor errors, holidays, etc.\n",
        "- **How**:\n",
        "  - **Forward fill / Backward fill**: Use previous/next value.\n",
        "    ```python\n",
        "    df['value'].fillna(method='ffill', inplace=True)\n",
        "    ```\n",
        "  - **Interpolation**: Linear or spline interpolation.\n",
        "    ```python\n",
        "    df['value'].interpolate(method='linear', inplace=True)\n",
        "    ```\n",
        "  - **Drop**: If too many missing or not useful.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Resampling**\n",
        "- **Why**: To convert data into a desired frequency (e.g., daily → monthly).\n",
        "- **How**:\n",
        "  ```python\n",
        "  df.resample('M').mean()  # Monthly average\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Removing Noise / Smoothing**\n",
        "- **Why**: Reduce high-frequency fluctuations to reveal trends.\n",
        "- **How**:\n",
        "  - **Moving Average**:\n",
        "    ```python\n",
        "    df['smoothed'] = df['value'].rolling(window=3).mean()\n",
        "    ```\n",
        "  - **Exponential Smoothing**\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Detrending**\n",
        "- **Why**: Many models assume **stationarity** (no trend).\n",
        "- **How**:\n",
        "  - Subtract a moving average or fitted trend line\n",
        "    ```python\n",
        "    df['detrended'] = df['value'] - df['value'].rolling(12).mean()\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Deseasonalizing**\n",
        "- **Why**: Some models work better without seasonality.\n",
        "- **How**:\n",
        "  - Use STL or seasonal decomposition to remove seasonal component\n",
        "    ```python\n",
        "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "    result = seasonal_decompose(df['value'], model='additive', period=12)\n",
        "    df['deseasonalized'] = df['value'] - result.seasonal\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Stationarity Checks & Transformations**\n",
        "- **Why**: Many time series models (ARIMA) require stationary data.\n",
        "- **How**:\n",
        "  - **Check with ADF test** (`statsmodels.tsa.stattools.adfuller`)\n",
        "  - Apply transformations:\n",
        "    - **Differencing**: Subtract current from previous value\n",
        "      ```python\n",
        "      df['diff'] = df['value'].diff()\n",
        "      ```\n",
        "    - **Log transform**: Stabilizes variance\n",
        "      ```python\n",
        "      df['log'] = np.log(df['value'])\n",
        "      ```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Time-Based Feature Engineering**\n",
        "- **Why**: For supervised learning models or seasonal insights.\n",
        "- **Examples**:\n",
        "  - Extract day, month, weekday, hour\n",
        "    ```python\n",
        "    df['month'] = df.index.month\n",
        "    df['weekday'] = df.index.weekday\n",
        "    ```\n",
        "  - Create lag features or rolling statistics:\n",
        "    ```python\n",
        "    df['lag_1'] = df['value'].shift(1)\n",
        "    df['rolling_mean_3'] = df['value'].rolling(3).mean()\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Normalization / Scaling (Optional)**\n",
        "- **Why**: For ML algorithms that are sensitive to scale.\n",
        "- **How**: Use Min-Max or StandardScaler\n",
        "  ```python\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  scaler = MinMaxScaler()\n",
        "  df[['value']] = scaler.fit_transform(df[['value']])\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "###  Summary Table\n",
        "\n",
        "| Step                 | Purpose                         |\n",
        "|----------------------|----------------------------------|\n",
        "| Handle Missing Data  | Fill gaps in time series         |\n",
        "| Resampling           | Uniform time intervals           |\n",
        "| Smoothing            | Remove short-term noise          |\n",
        "| Detrending           | Remove long-term trend           |\n",
        "| Deseasonalizing      | Remove seasonal effects          |\n",
        "| Stationarity Check   | Ensure stability of stats        |\n",
        "| Feature Engineering  | Add useful time-based features   |\n",
        "| Scaling              | Normalize data for ML models     |"
      ],
      "metadata": {
        "id": "tmUyPprAMxo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. How can time series forecasting be used in business decision-making, and what are some common challenges and limitations?\n",
        "Ans: \\\n",
        "\n",
        "###  **1. Sales Forecasting**\n",
        "- **Use Case**: Predict future sales volumes to manage inventory, staffing, and promotions.\n",
        "- **Example**: A retailer forecasts demand for winter coats based on past seasonal trends.\n",
        "\n",
        "---\n",
        "\n",
        "###  **2. Inventory Management**\n",
        "- **Use Case**: Forecast product demand to optimize stock levels.\n",
        "- **Example**: An e-commerce platform avoids overstock or stockouts using demand predictions.\n",
        "\n",
        "---\n",
        "\n",
        "###  **3. Financial Planning**\n",
        "- **Use Case**: Predict revenue, cash flow, or expenses.\n",
        "- **Example**: A SaaS company forecasts monthly recurring revenue (MRR) for the next quarter.\n",
        "\n",
        "---\n",
        "\n",
        "###  **4. Energy Load Forecasting**\n",
        "- **Use Case**: Predict electricity/water/gas usage to balance supply and demand.\n",
        "- **Example**: Power companies use time series to forecast peak load hours.\n",
        "\n",
        "---\n",
        "\n",
        "###  **5. Website Traffic & User Engagement**\n",
        "- **Use Case**: Forecast web visits to allocate server resources or marketing budgets.\n",
        "- **Example**: A news site prepares for increased traffic during election season.\n",
        "\n",
        "---\n",
        "\n",
        "###  **6. Capacity and Workforce Planning**\n",
        "- **Use Case**: Predict how many staff members are needed at different times.\n",
        "- **Example**: Airlines forecast passenger volumes to schedule flights and crew shifts.\n",
        "\n",
        "---\n",
        "\n",
        "##  Challenges & Limitations of Time Series Forecasting\n",
        "\n",
        "|  Challenge                  |  Explanation |\n",
        "|------------------------------|----------------|\n",
        "| **1. Seasonality/Cycles**     | Data may have complex or irregular seasonal patterns that are hard to model. |\n",
        "| **2. Data Quality Issues**    | Missing, inconsistent, or noisy data can ruin forecasts. |\n",
        "| **3. External Events**        | Unexpected events (e.g., COVID-19, weather, political changes) break usual patterns. |\n",
        "| **4. Model Overfitting**      | Overly complex models may perform well on past data but poorly on future data. |\n",
        "| **5. Non-stationarity**       | Many models assume constant mean/variance, but real data may drift over time. |\n",
        "| **6. Limited History**        | Short or sparse historical records make pattern detection hard. |\n",
        "| **7. Multiple Influencing Factors** | Time series alone may not account for marketing, competition, or price changes. |\n",
        "| **8. Lead Time Limitations**  | Accuracy often decreases the further out you forecast. |\n",
        "\n",
        "---\n",
        "\n",
        "##  How to Tackle These Challenges?\n",
        "\n",
        "- Use **exogenous variables** (external features like promotions, holidays).\n",
        "- Combine models (e.g., ARIMA + ML, ensemble models).\n",
        "- Regularly **retrain models** to adapt to new trends.\n",
        "- Monitor performance with rolling forecasts and validation.\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Thought\n",
        "\n",
        "Time series forecasting is a **powerful decision-making tool** across industries — but it’s not magic. You need:\n",
        "- Good historical data,\n",
        "- Domain knowledge,\n",
        "- And continuous model evaluation to keep it effective."
      ],
      "metadata": {
        "id": "-aQx-R5rNyKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. What is ARIMA modelling, and how can it be used to forecast time series data?\n",
        "Ans: \\\n",
        "\n",
        "**ARIMA** stands for:\n",
        "\n",
        "> **AutoRegressive Integrated Moving Average**\n",
        "\n",
        "It is a **statistical model** used to analyze and forecast time series data by capturing:\n",
        "- Autocorrelations (past values influence future ones)\n",
        "- Trends (non-stationarity)\n",
        "- Noise/smoothness in the data\n",
        "\n",
        "---\n",
        "\n",
        "###  ARIMA(p, d, q) – What Do the Parameters Mean?\n",
        "\n",
        "| Component | Description                                                  |\n",
        "|----------|--------------------------------------------------------------|\n",
        "| **p**    | Number of **AutoRegressive (AR)** terms – how many past values are used |\n",
        "| **d**    | Number of times to **difference** the series to make it stationary |\n",
        "| **q**    | Number of **Moving Average (MA)** terms – how many past forecast errors are used |\n",
        "\n",
        "---\n",
        "\n",
        "###  Intuition Behind Each Component\n",
        "\n",
        "- **AR (p)**: “Today’s value depends on the past few days’ values.”\n",
        "- **I (d)**: “The trend needs to be removed to make the data stable.”\n",
        "- **MA (q)**: “Today’s value also depends on past forecast errors.”\n",
        "\n",
        "---\n",
        "\n",
        "###  When to Use ARIMA?\n",
        "\n",
        " Use ARIMA when:\n",
        "- Your data shows **trend**, but **not strong seasonality**.\n",
        "- You want a **statistical, interpretable model**.\n",
        "- You’ve already made the data **stationary** (or are willing to difference it).\n",
        "\n",
        "---\n",
        "\n",
        "###  How ARIMA Forecasts Time Series\n",
        "\n",
        "1. **Check Stationarity** (using ADF test or plot)\n",
        "2. **Difference the series** if it's non-stationary (that’s the \"I\")\n",
        "3. **Plot ACF and PACF** to estimate `p` and `q`\n",
        "4. **Fit ARIMA(p,d,q)** model\n",
        "5. **Use model to forecast future values**\n",
        "\n",
        "###  Model Evaluation Metrics\n",
        "\n",
        "- **MAE (Mean Absolute Error)**\n",
        "- **RMSE (Root Mean Squared Error)**\n",
        "- **AIC/BIC** for model selection\n",
        "\n",
        "---\n",
        "\n",
        "###  Extensions of ARIMA\n",
        "\n",
        "| Model    | Use Case                                      |\n",
        "|----------|-----------------------------------------------|\n",
        "| **SARIMA** | ARIMA + Seasonality (for seasonal data)       |\n",
        "| **ARIMAX** | ARIMA + Exogenous variables (promo, holidays) |\n",
        "| **Auto-ARIMA** | Automatically finds best (p,d,q) values     |\n",
        "\n",
        "---\n",
        "\n",
        "##  Summary\n",
        "\n",
        "| Feature         | Description                      |\n",
        "|------------------|----------------------------------|\n",
        "| **What**         | Statistical model for time series |\n",
        "| **Components**   | AR (p), I (d), MA (q)             |\n",
        "| **Best for**     | Trend-based data (non-seasonal)  |\n",
        "| **Tools**        | `statsmodels`, `pmdarima`         |"
      ],
      "metadata": {
        "id": "7f_rWj4-OjA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load time series (e.g., monthly airline passengers)\n",
        "data = pd.read_csv('example.csv', index_col='Month', parse_dates=True)\n",
        "series = data['#Passengers']\n",
        "\n",
        "# Fit ARIMA(p=1, d=1, q=1)\n",
        "model = ARIMA(series, order=(1,1,1))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Forecast next 12 months\n",
        "forecast = model_fit.forecast(steps=12)\n",
        "\n",
        "# Plot\n",
        "plt.plot(series, label=\"Historical\")\n",
        "plt.plot(forecast, label=\"Forecast\", color='red')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8ZFWGXR7PdyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6. How do Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots help in identifying the order of ARIMA models?\n",
        "Ans: \\\n",
        "\n",
        "###  What Are ACF and PACF?\n",
        "\n",
        "| Function | What it Measures                                      | Used For                |\n",
        "|----------|--------------------------------------------------------|--------------------------|\n",
        "| **ACF** (Autocorrelation Function) | Correlation between a time series and its **past values (lags)** | Helps choose **MA(q)** |\n",
        "| **PACF** (Partial Autocorrelation Function) | Correlation of the series with its **lag**, excluding effects of intermediate lags | Helps choose **AR(p)** |\n",
        "\n",
        "---\n",
        "\n",
        "###  Intuition:\n",
        "\n",
        "- ACF: “How much does the value today depend on previous days?”\n",
        "- PACF: “After accounting for the influence of lag 1, how much does lag 2 matter?”\n",
        "\n",
        "---\n",
        "\n",
        "##  How They Help Select ARIMA Parameters:\n",
        "\n",
        "| Plot Type | Cut-off Pattern Suggests...        | ARIMA Component |\n",
        "|-----------|-------------------------------------|-----------------|\n",
        "| **ACF**   | Sharp drop-off after lag `q`       | Choose MA(`q`)  |\n",
        "| **PACF**  | Sharp drop-off after lag `p`       | Choose AR(`p`)  |\n",
        "\n",
        "\n",
        "##  Quick ARIMA Parameter Selection Guide\n",
        "\n",
        "| Pattern Seen                | Suggested ARIMA Model |\n",
        "|----------------------------|------------------------|\n",
        "| PACF cuts off at lag `p`, ACF tapers | ARIMA(p, d, 0)         |\n",
        "| ACF cuts off at lag `q`, PACF tapers | ARIMA(0, d, q)         |\n",
        "| Both taper off              | ARIMA(p, d, q)         |\n",
        "\n",
        "---\n",
        "\n",
        "###  Bonus Tip: Combine With AIC/BIC\n",
        "\n",
        "Once you get a **range of candidate values for p and q** from ACF/PACF, you can try multiple models and choose the one with the **lowest AIC/BIC** (goodness-of-fit criteria)."
      ],
      "metadata": {
        "id": "0mSa5JnOPOvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7. What are the assumptions of ARIMA models, and how can they be tested for in practice?\n",
        "Ans: \\\n",
        "ARIMA (AutoRegressive Integrated Moving Average) models are widely used for time series forecasting. When applying ARIMA models, several assumptions should ideally be met for the model to produce reliable and accurate forecasts. Here's an overview of the key assumptions and how to test them in practice:\n",
        "\n",
        "### 1. **Stationarity of the Time Series**\n",
        "   **Assumption**: The underlying time series should be stationary, meaning that its statistical properties, such as mean, variance, and autocorrelation, are constant over time. ARIMA models require the series to be stationary before fitting.\n",
        "\n",
        "   **How to Test**:\n",
        "   - **Augmented Dickey-Fuller (ADF) test**: A formal test for stationarity that checks for the presence of unit roots (which would indicate non-stationarity).\n",
        "   - **Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test**: Another test for stationarity that tests the null hypothesis of stationarity.\n",
        "   - **Visual inspection**: Plotting the time series and examining for trends, seasonality, or other non-stationary behaviors.\n",
        "   - **ACF/PACF plots**: If the autocorrelation function (ACF) and partial autocorrelation function (PACF) plots show significant autocorrelation at various lags, the series might be non-stationary.\n",
        "\n",
        "   **Solution if Non-Stationary**: Differencing the series (integrating) to remove trends or seasonality.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **No Serial Correlation in Residuals**\n",
        "   **Assumption**: The residuals (errors) of the ARIMA model should not show any significant autocorrelation. If there is serial correlation in the residuals, it indicates that the model has not captured all of the patterns in the data.\n",
        "\n",
        "   **How to Test**:\n",
        "   - **Ljung-Box test**: This tests whether the residuals from the ARIMA model exhibit significant autocorrelation at any lag.\n",
        "   - **ACF of residuals**: Plot the autocorrelation function of the residuals. Ideally, the residuals should have no significant correlations.\n",
        "   \n",
        "   **Solution if Serial Correlation Exists**: Reevaluate the model's parameters (p, d, q) or try different model types.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Normally Distributed Residuals**\n",
        "   **Assumption**: The residuals of the ARIMA model should ideally be normally distributed for hypothesis testing (e.g., confidence intervals, predictions).\n",
        "\n",
        "   **How to Test**:\n",
        "   - **Q-Q plot**: A quantile-quantile plot can be used to compare the residuals to a normal distribution.\n",
        "   - **Shapiro-Wilk test**: A formal statistical test for normality.\n",
        "   - **Skewness and Kurtosis**: Check if the skewness and kurtosis of the residuals deviate significantly from 0 and 3, respectively.\n",
        "\n",
        "   **Solution if Residuals Are Not Normal**: While ARIMA can work even if residuals aren't perfectly normal, consider transforming the data (e.g., log transformation) or using a different model if normality is crucial.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Linearity**\n",
        "   **Assumption**: The relationship between the time series and its lagged values (both autoregressive and moving average components) is assumed to be linear.\n",
        "\n",
        "   **How to Test**:\n",
        "   - **Residual analysis**: If the residuals show a nonlinear pattern or structure, this assumption may be violated.\n",
        "   - **Nonlinear models**: You can try fitting nonlinear models such as neural networks or other machine learning techniques if the residuals exhibit significant nonlinear patterns.\n",
        "\n",
        "   **Solution if Nonlinearity Exists**: Consider using nonlinear models like GARCH, SARIMA (Seasonal ARIMA), or machine learning models that can handle nonlinear relationships.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **No Strong Seasonal Effects (for Non-Seasonal ARIMA)**\n",
        "   **Assumption**: For non-seasonal ARIMA, it’s assumed there are no strong seasonal patterns in the data. If seasonal effects are present, the seasonal version of ARIMA (SARIMA) should be used.\n",
        "\n",
        "   **How to Test**:\n",
        "   - **Seasonal decomposition**: Use techniques like STL decomposition (Seasonal-Trend decomposition using LOESS) to separate out the seasonal component.\n",
        "   - **Seasonal ACF/PACF**: Check if there are repeating patterns at seasonal lags in the ACF and PACF plots.\n",
        "\n",
        "   **Solution if Seasonality Exists**: Use the SARIMA model, which extends ARIMA by adding seasonal components (P, D, Q, S).\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Constant Variance (Homoscedasticity)**\n",
        "   **Assumption**: The variance of the residuals should be constant over time (i.e., no heteroscedasticity). If the variance changes over time, this can affect the accuracy of forecasts.\n",
        "\n",
        "   **How to Test**:\n",
        "   - **Visual inspection**: Plotting the residuals over time should show no clear pattern or changing spread.\n",
        "   - **Breusch-Pagan test** or **White test**: Formal tests for heteroscedasticity.\n",
        "\n",
        "   **Solution if Heteroscedasticity Exists**: You might need to use a model that can account for changing variance, such as GARCH (Generalized Autoregressive Conditional Heteroskedasticity).\n",
        "\n",
        "---\n",
        "\n",
        "### Practical Steps:\n",
        "1. **Stationarity**: Perform ADF/KPSS tests and consider differencing if needed.\n",
        "2. **Serial Correlation**: Use the Ljung-Box test and ACF/PACF plots for residuals.\n",
        "3. **Normality of Residuals**: Use Q-Q plots, Shapiro-Wilk test, and examine skewness/kurtosis.\n",
        "4. **Linearity**: Inspect residuals and consider nonlinear models if necessary.\n",
        "5. **Seasonality**: Use seasonal decomposition or SARIMA if seasonality is present.\n",
        "6. **Homoscedasticity**: Check for constant variance using residual plots or formal tests."
      ],
      "metadata": {
        "id": "DeFfQTeJQL56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8. Suppose you have monthly sales data for a retail store for the past three years. Which type of time series model would you recommend for forecasting future sales, and why?\n",
        "Ans: \\\n",
        " Here's a breakdown of the types of models you might consider, along with the reasoning behind each:\n",
        "\n",
        "### 1. **ARIMA (AutoRegressive Integrated Moving Average)**\n",
        "   - **Recommended If**: The sales data shows a **trend** but no strong seasonal patterns.\n",
        "   - **Why**:\n",
        "     - ARIMA is a good choice for **non-seasonal data** with trends (either increasing or decreasing) over time.\n",
        "     - If the data is non-stationary (e.g., if there is a long-term trend), differencing (the \"I\" part of ARIMA) can help make it stationary.\n",
        "     - ARIMA can model the relationship between past values (autoregressive component) and past errors (moving average component).\n",
        "\n",
        "   - **Steps**:\n",
        "     1. **Check for Stationarity**: Use tests like ADF (Augmented Dickey-Fuller) test or visually inspect the series. If the data is non-stationary, apply differencing.\n",
        "     2. **Build ARIMA Model**: Select appropriate values for the parameters p (AR order), d (degree of differencing), and q (MA order), potentially using grid search or auto-arima functions to optimize.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **SARIMA (Seasonal ARIMA)**\n",
        "   - **Recommended If**: The sales data shows **seasonality** (e.g., higher sales during holidays, certain months, or seasons).\n",
        "   - **Why**:\n",
        "     - If the data exhibits clear seasonal patterns (such as spikes in sales during certain months every year), SARIMA is a better choice because it extends ARIMA to account for **seasonality**.\n",
        "     - SARIMA includes additional seasonal parameters that model the seasonal autoregressive (SAR), seasonal differencing (SD), and seasonal moving average (SMA) components, which are specifically designed to capture seasonal patterns.\n",
        "     \n",
        "   - **Steps**:\n",
        "     1. **Identify Seasonality**: Look at autocorrelation plots or decompose the time series using methods like STL (Seasonal and Trend decomposition using Loess) to isolate seasonal components.\n",
        "     2. **Build SARIMA Model**: Choose the seasonal order parameters (P, D, Q, S) based on the frequency of the seasonality (e.g., S=12 for monthly data with yearly seasonality) and fit the SARIMA model.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Exponential Smoothing (Holt-Winters)**\n",
        "   - **Recommended If**: The sales data has both **trend and seasonality**.\n",
        "   - **Why**:\n",
        "     - Exponential smoothing methods (e.g., **Holt-Winters** method) are useful when the time series data exhibits both **trend and seasonality**.\n",
        "     - The Holt-Winters method can model **additive or multiplicative seasonality** and **trends** in a time series. It’s easy to apply and can adapt to both short-term and long-term forecasting.\n",
        "     \n",
        "   - **Steps**:\n",
        "     1. **Check for Trend and Seasonality**: Visual inspection and seasonal decomposition.\n",
        "     2. **Apply Holt-Winters**: Choose between additive or multiplicative models depending on the nature of the trend and seasonality. In the additive model, the seasonal effect is constant over time, while in the multiplicative model, it grows or shrinks with the level of the series.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Prophet (by Facebook)**\n",
        "   - **Recommended If**: The sales data shows **complex seasonality** and/or **holiday effects**.\n",
        "   - **Why**:\n",
        "     - Prophet is a **flexible and robust** model designed to handle time series data with strong seasonal effects, multiple seasonality (e.g., weekly, yearly), holidays, and missing data.\n",
        "     - It can handle nonlinear trends and outliers well and is very useful when the seasonal effects are irregular or difficult to model explicitly.\n",
        "     \n",
        "   - **Steps**:\n",
        "     1. **Prepare Data**: Prophet requires data in a specific format with columns for \"ds\" (date) and \"y\" (value).\n",
        "     2. **Model Fit**: Prophet automatically captures seasonality and can incorporate special events (like holidays) by specifying them explicitly.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Machine Learning Models (e.g., Random Forest, XGBoost)**\n",
        "   - **Recommended If**: You want to capture complex relationships and have additional features like **promotions, holidays**, or **weather** that might influence sales.\n",
        "   - **Why**:\n",
        "     - Machine learning models like Random Forest or XGBoost are **non-parametric** and can capture complex, nonlinear relationships in the data.\n",
        "     - These models can handle a large number of input features (such as promotions, store openings, and economic factors) that could improve forecasting accuracy.\n",
        "     - They are typically used when traditional time series models do not capture the complexities of the data well.\n",
        "\n",
        "   - **Steps**:\n",
        "     1. **Feature Engineering**: Create relevant features such as time of year, promotions, or external factors.\n",
        "     2. **Model Training**: Train a model using past sales data along with additional features and validate using cross-validation.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Recommendation:\n",
        "\n",
        "- If **seasonality** and **trend** are both present in your data (which is typical for retail sales), **SARIMA** or **Holt-Winters Exponential Smoothing** would be strong candidates.\n",
        "- If you want a **flexible approach** that can handle complex seasonal patterns, **Prophet** is a great tool.\n",
        "- For purely **non-seasonal data with trend** but no complex seasonality, **ARIMA** might be sufficient.\n",
        "- If your data includes a lot of external factors (e.g., promotions, holidays), **machine learning models** might provide better accuracy."
      ],
      "metadata": {
        "id": "192VCx-aRP0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q9. What are some of the limitations of time series analysis? Provide an example of a scenario where the limitations of time series analysis may be particularly relevant.\n",
        "Ans: \\\n",
        "some limitations of time series analysis include:\n",
        "\n",
        "1. **Stationarity Assumption**: Many models assume data is stationary (constant mean and variance over time), which isn't always the case.\n",
        "   \n",
        "2. **Non-Linear Relationships**: Time series models (like ARIMA) struggle with non-linear data patterns, often seen in complex systems.\n",
        "\n",
        "3. **Overfitting**: Models can overfit historical noise, leading to poor generalization to future data.\n",
        "\n",
        "4. **External Factors**: Time series models often don't account for external influences (e.g., economic events, policy changes).\n",
        "\n",
        "5. **Seasonality Changes**: Fixed seasonality assumptions may not work well if seasonality patterns shift over time.\n",
        "\n",
        "6. **Sensitivity to Outliers**: Outliers or missing data can significantly distort model performance.\n",
        "\n",
        "7. **Long-Term Forecasting**: Accuracy diminishes as the forecast horizon extends, due to accumulating errors.\n",
        "\n",
        "### Example Scenario:\n",
        "In **stock market forecasting**, where trends change suddenly due to geopolitical events or economic crises, time series models may fail to account for such external shocks and exhibit poor forecasting accuracy."
      ],
      "metadata": {
        "id": "r88uYwHjSNkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q10. Explain the difference between a stationary and non-stationary time series. How does the stationarity of a time series affect the choice of forecasting model?\n",
        "Ans: \\\n",
        "\n",
        "1. **Stationary Time Series**:\n",
        "   - A stationary time series has **constant statistical properties** over time, including:\n",
        "     - **Constant mean**: The average value of the series does not change over time.\n",
        "     - **Constant variance**: The variability of the data is constant over time.\n",
        "     - **Constant autocorrelation**: The relationships between past and future values remain the same over time.\n",
        "   \n",
        "   - Example: Monthly sales data of a store where the average sales and variance remain roughly the same over time (no trends or seasonal effects).\n",
        "\n",
        "2. **Non-Stationary Time Series**:\n",
        "   - A non-stationary time series has **changing statistical properties** over time. These changes could include:\n",
        "     - **Trends**: The mean of the data changes over time (e.g., increasing or decreasing).\n",
        "     - **Seasonality**: The data exhibits periodic fluctuations that repeat over time.\n",
        "     - **Changing variance**: The variability in the data increases or decreases over time.\n",
        "   \n",
        "   - Example: Stock prices that tend to have long-term upward or downward trends and fluctuating variance due to market conditions.\n",
        "\n",
        "---\n",
        "\n",
        "### How Stationarity Affects the Choice of Forecasting Model:\n",
        "\n",
        "1. **Stationary Series**:\n",
        "   - For stationary series, models like **ARIMA** are suitable. Since the statistical properties of the data do not change over time, these models can capture the relationships between past values (autoregressive and moving average components) and make reliable predictions.\n",
        "\n",
        "   - **Model Choice**:\n",
        "     - **ARIMA (AutoRegressive Integrated Moving Average)** is commonly used for stationary time series. ARIMA assumes that the series is already stationary or has been made stationary through differencing.\n",
        "\n",
        "2. **Non-Stationary Series**:\n",
        "   - Non-stationary series often require **preprocessing** (e.g., differencing, transformation) to make them stationary before applying forecasting models like ARIMA.\n",
        "     - **Differencing**: Subtracting the previous observation from the current observation (this can help remove trends).\n",
        "     - **Seasonal Differencing**: For seasonal data, differencing at seasonal lags can remove seasonal effects.\n",
        "   - If the series exhibits seasonal behavior, models like **SARIMA** (Seasonal ARIMA) or **Exponential Smoothing** might be more appropriate.\n",
        "\n",
        "   - **Model Choice**:\n",
        "     - **SARIMA (Seasonal ARIMA)**: For series with both trend and seasonality.\n",
        "     - **Holt-Winters Exponential Smoothing**: For series with trend and seasonal patterns.\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusion:\n",
        "- **Stationary** series are easier to model and predict with traditional methods like ARIMA.\n",
        "- **Non-stationary** series require preprocessing (like differencing) to make them stationary before applying standard time series models. Alternatively, models like SARIMA or machine learning approaches might be better suited for non-stationary data."
      ],
      "metadata": {
        "id": "NxRJWGUSStn2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2UrZbIyLo9K"
      },
      "outputs": [],
      "source": []
    }
  ]
}