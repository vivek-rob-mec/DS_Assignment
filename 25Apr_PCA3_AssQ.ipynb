{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###  Q1. **What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example.**\n",
        "Ans: \\\n",
        "\n",
        "**Eigenvalues** and **Eigenvectors** are fundamental concepts in linear algebra that describe the behavior of a matrix when it is multiplied by certain vectors.\n",
        "\n",
        "- **Eigenvector**: A non-zero vector that, when a matrix is multiplied by it, changes only in scale (i.e., gets stretched or compressed) but not in direction.\n",
        "- **Eigenvalue**: The scalar by which the eigenvector is scaled during the multiplication by the matrix.\n",
        "\n",
        "In the **Eigen-Decomposition approach**, a matrix \\( A \\) can be decomposed into a set of eigenvectors and eigenvalues. The matrix \\( A \\) can be represented as:\n",
        "\n",
        "$$[\n",
        "A = V \\cdot \\Lambda \\cdot V^{-1}\n",
        "]$$\n",
        "\n",
        "Where:\n",
        "- \\( V \\) is a matrix containing the eigenvectors.\n",
        "- $( \\Lambda )$ is a diagonal matrix containing the eigenvalues.\n",
        "\n",
        "#### Example:\n",
        "Let’s say we have a matrix:\n",
        "\n",
        "$$[\n",
        "A = \\begin{bmatrix} 4 & 1 \\\\ 2 & 3 \\end{bmatrix}\n",
        "]$$\n",
        "\n",
        "Eigenvectors and eigenvalues can be found by solving the equation:\n",
        "\n",
        "$$[\n",
        "A \\cdot v = \\lambda \\cdot v\n",
        "]$$\n",
        "\n",
        "Where \\( v \\) is the eigenvector and \\( \\lambda \\) is the eigenvalue.\n",
        "\n",
        "For this matrix, after solving for the eigenvalues and eigenvectors, we get:\n",
        "\n",
        "- Eigenvalues: $( \\lambda_1 = 5, \\lambda_2 = 2 )$\n",
        "- Eigenvectors: $( v_1 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, v_2 = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix} )$\n",
        "\n",
        "---\n",
        "\n",
        "###  Q2. **What is eigen decomposition and what is its significance in linear algebra?**\n",
        "Ans: \\\n",
        "\n",
        "**Eigen Decomposition** refers to the process of breaking down a matrix into its eigenvalues and eigenvectors. For a square matrix \\( A \\), if it is diagonalizable, we can express it as:\n",
        "\n",
        "$$[\n",
        "A = V \\cdot \\Lambda \\cdot V^{-1}\n",
        "]$$\n",
        "\n",
        "Where:\n",
        "- \\( V \\) is the matrix of eigenvectors.\n",
        "- $( \\Lambda )$ is the diagonal matrix of eigenvalues.\n",
        "- $( V^{-1} )$ is the inverse of \\( V \\).\n",
        "\n",
        "The significance of eigen decomposition:\n",
        "- It helps in simplifying matrix operations, especially powers and functions of matrices.\n",
        "- It plays a vital role in **diagonalization**, making computations easier in many mathematical problems, such as solving differential equations and in stability analysis.\n",
        "\n",
        "---\n",
        "\n",
        "###  Q3. **What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer.**\n",
        "Ans: \\\n",
        "\n",
        "For a matrix to be diagonalizable using **Eigen-Decomposition**, it must satisfy the following conditions:\n",
        "1. The matrix must have **n linearly independent eigenvectors** (where n is the size of the matrix).\n",
        "2. The matrix must be **square**.\n",
        "\n",
        "#### Proof:\n",
        "For a square matrix \\( A \\), if it has **n linearly independent eigenvectors**, we can construct the matrix \\( V \\) with these eigenvectors as columns. Since \\( V \\) is composed of linearly independent vectors, it will be invertible. Then, the matrix can be diagonalized as:\n",
        "\n",
        "$$[\n",
        "A = V \\cdot \\Lambda \\cdot V^{-1}\n",
        "]$$\n",
        "\n",
        "This shows that the matrix \\( A \\) can be diagonalized if it has **n linearly independent eigenvectors**.\n",
        "\n",
        "---\n",
        "\n",
        "###  Q4. **What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example.**\n",
        "\n",
        "The **Spectral Theorem** states that any **symmetric matrix** can be diagonalized by an orthogonal matrix, meaning its eigenvectors can be chosen to be orthogonal. The matrix can be written as:\n",
        "\n",
        "$$[\n",
        "A = V \\cdot \\Lambda \\cdot V^T\n",
        "]$$\n",
        "\n",
        "Where \\( V \\) is an orthogonal matrix $(i.e., ( V^T = V^{-1} )) and ( \\Lambda )$ is the diagonal matrix of eigenvalues.\n",
        "\n",
        "#### Example:\n",
        "Consider the symmetric matrix:\n",
        "\n",
        "$$[\n",
        "A = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n",
        "]$$\n",
        "\n",
        "The eigenvalues of \\( A \\) are 3 and 1, and the eigenvectors are orthogonal. Therefore, \\( A \\) is diagonalizable, and the spectral theorem guarantees this diagonalization.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Q5. **How do you find the eigenvalues of a matrix and what do they represent?**\n",
        "Ans:\n",
        "To find the **eigenvalues** of a matrix \\( A \\), we solve the **characteristic equation**:\n",
        "\n",
        "$$[\n",
        "\\text{det}(A - \\lambda I) = 0\n",
        "]$$\n",
        "\n",
        "Where:\n",
        "- \\( A \\) is the matrix.\n",
        "- $( \\lambda )$ is the eigenvalue.\n",
        "- \\( I \\) is the identity matrix.\n",
        "\n",
        "The solutions $( \\lambda )$ are the eigenvalues of the matrix.\n",
        "\n",
        "#### What do eigenvalues represent?\n",
        "- Eigenvalues measure the **scaling factor** by which the matrix stretches or compresses a vector along a certain direction.\n",
        "- In physical systems, they can represent **frequencies** in vibration analysis or the **stability** of systems.\n",
        "\n",
        "---\n",
        "\n",
        "###  Q6. **What are eigenvectors and how are they related to eigenvalues?**\n",
        "Ans: \\\n",
        "\n",
        "**Eigenvectors** are vectors that, when a matrix \\( A \\) is applied to them, change only in magnitude (scaling) but not in direction. The matrix acts on the eigenvector by scaling it by the corresponding **eigenvalue**.\n",
        "\n",
        "- Eigenvectors provide the **direction** along which the matrix stretches or compresses.\n",
        "- Eigenvalues determine the **amount** by which the eigenvector is stretched or compressed.\n",
        "\n",
        "For a matrix \\( A \\) and eigenvector \\( v \\):\n",
        "\n",
        "$$[\n",
        "A \\cdot v = \\lambda \\cdot v\n",
        "]$$\n",
        "\n",
        "Where \\( \\lambda \\) is the eigenvalue corresponding to the eigenvector \\( v \\).\n",
        "\n",
        "---\n",
        "\n",
        "###  Q7. **Can you explain the geometric interpretation of eigenvectors and eigenvalues?**\n",
        "Ans: \\\n",
        "\n",
        "- **Eigenvectors** represent directions in space that remain unchanged (except for scaling) when a matrix transformation is applied.\n",
        "- **Eigenvalues** represent how much the data is stretched or compressed along the eigenvector direction.\n",
        "  \n",
        "#### Example:\n",
        "Imagine a 2D matrix transformation that squashes or stretches the data:\n",
        "- Eigenvectors are the **directions** along which the data is **stretched** or **compressed**.\n",
        "- Eigenvalues are the **factors** by which the stretching or compression occurs.\n",
        "\n",
        "---\n",
        "\n",
        "###  Q8. **What are some real-world applications of eigen decomposition?**\n",
        "Ans:\\\n",
        "\n",
        "1. **Principal Component Analysis (PCA)**:  \n",
        "   Eigen decomposition is used to reduce the dimensionality of data, preserving the directions with the most variance.\n",
        "   \n",
        "2. **Vibration Analysis**:  \n",
        "   In engineering, eigenvalues represent the natural frequencies of a vibrating system.\n",
        "\n",
        "3. **Graph Theory**:  \n",
        "   Eigenvectors of a graph’s adjacency matrix are used in spectral clustering.\n",
        "\n",
        "4. **Quantum Mechanics**:  \n",
        "   Eigenvalues and eigenvectors represent observable quantities in quantum systems.\n",
        "\n",
        "---\n",
        "\n",
        "###  Q9. **Can a matrix have more than one set of eigenvectors and eigenvalues?**\n",
        "Ans: \\\n",
        "\n",
        "Yes, a matrix can have multiple **sets of eigenvectors** and **eigenvalues**, particularly if:\n",
        "- The matrix has **repeated eigenvalues** (degeneracy).\n",
        "- Multiple eigenvectors can correspond to the same eigenvalue, forming a **subspace**.\n",
        "\n",
        "However, each eigenvalue has a **unique set of eigenvectors** (up to scaling) associated with it.\n",
        "\n",
        "---\n",
        "\n",
        "###  Q10. **In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning? Discuss at least three specific applications or techniques that rely on Eigen-Decomposition.**\n",
        "Ans: \\\n",
        "\n",
        "1. **Principal Component Analysis (PCA)**:\n",
        "   PCA uses eigenvectors and eigenvalues to reduce the dimensionality of data by finding directions (principal components) that explain the most variance in the data.\n",
        "\n",
        "2. **Spectral Clustering**:\n",
        "   In clustering, eigen-decomposition of the graph Laplacian helps identify clusters by finding the eigenvectors corresponding to the smallest eigenvalues.\n",
        "\n",
        "3. **Face Recognition (Eigenfaces)**:\n",
        "   In face recognition, eigen-decomposition helps extract the main features (eigenfaces) of face images, which can be used for efficient face classification."
      ],
      "metadata": {
        "id": "hzEeCINvQuGt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZoaLtcaiSZvq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}